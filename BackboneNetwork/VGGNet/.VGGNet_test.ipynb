{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGGNet\n",
    "Training example using MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_builder = tfds.builder(\"cifar100\")\n",
    "data_builder.download_and_prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data_builder.as_dataset(split=tfds.Split.TRAIN)\n",
    "val_dataset = data_builder.as_dataset(split=tfds.Split.TEST)\n",
    "\n",
    "num_classes = data_builder.info.features['label'].num_classes\n",
    "\n",
    "num_train = data_builder.info.splits['train'].num_examples\n",
    "num_val = data_builder.info.splits['test'].num_examples\n",
    "\n",
    "print('# for train : %d'%(num_train))\n",
    "print('# for valid : %d'%(num_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [224, 224, 3]\n",
    "\n",
    "batch_size = 16\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv3_64 = functools.partial(Conv2D,\n",
    "                            filters=64,\n",
    "                            kernel_size=(3, 3),\n",
    "                            padding='same',\n",
    "                            activation='relu')\n",
    "\n",
    "Conv3_128 = functools.partial(Conv2D,\n",
    "                             filters=128,\n",
    "                             kernel_size=(3, 3),\n",
    "                             padding='same',\n",
    "                             activation='relu')\n",
    "\n",
    "Conv3_256 = functools.partial(Conv2D,\n",
    "                             filters=256,\n",
    "                             kernel_size=(3, 3),\n",
    "                             padding='same',\n",
    "                             activation='relu')\n",
    "\n",
    "Conv3_512 = functools.partial(Conv2D,\n",
    "                             filters=512,\n",
    "                             kernel_size=(3, 3),\n",
    "                             padding='same',\n",
    "                             activation='relu')\n",
    "Dense_4096 = functools.partial(Dense,\n",
    "                          units=4096, \n",
    "                          kernel_regularizer=tf.keras.regularizers.L2(0.0005),\n",
    "                          activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGGNet(input_shape, num_classes, model_type: 16 or 19 =16):    \n",
    "    input = Input(shape=input_shape, name='Input')\n",
    "    \n",
    "    x = Conv3_64(name='block1_conv1')(input)\n",
    "    x = Conv3_64(name='block1_conv2')(x)\n",
    "    x = MaxPooling2D(pool_size=2, padding='same', name='block1_pool')(x)\n",
    "    \n",
    "    x = Conv3_128(name='block2_conv1')(x)\n",
    "    x = Conv3_128(name='block2_conv2')(x)\n",
    "    x = MaxPooling2D(pool_size=2, padding='same', name='block2_pool')(x)\n",
    "    \n",
    "    x = Conv3_256(name='block3_conv1')(x)\n",
    "    x = Conv3_256(name='block3_conv2')(x)\n",
    "    x = Conv3_256(name='block3_conv3')(x)\n",
    "    if model_type == 19:\n",
    "        x = Conv3_256(name='block3_conv4')(x)\n",
    "    x = MaxPooling2D(pool_size=2, padding='same', name='block3_pool')(x)\n",
    "    \n",
    "    x = Conv3_512(name='block4_conv1')(x)\n",
    "    x = Conv3_512(name='block4_conv2')(x)\n",
    "    x = Conv3_512(name='block4_conv3')(x)\n",
    "    if model_type == 19:\n",
    "        x = Conv3_512(name='block4_conv4')(x)\n",
    "    x = MaxPooling2D(pool_size=2, padding='same', name='block4_pool')(x)\n",
    "    \n",
    "    x = Conv3_512(name='block5_conv1')(x)\n",
    "    x = Conv3_512(name='block5_conv2')(x)\n",
    "    x = Conv3_512(name='block5_conv3')(x)\n",
    "    if model_type == 19:\n",
    "        x = Conv3_512(name='block5_conv4')(x)\n",
    "    x = MaxPooling2D(pool_size=2, padding='same', name='block5_pool')(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense_4096(name='fc1')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense_4096(name='fc2')(x)  \n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(num_classes, activation='softmax', name='ouput')(x)\n",
    "\n",
    "    model = Model(inputs=input, outputs=output)\n",
    "    if model_type == 19:\n",
    "        model._name = 'VGG19'\n",
    "    else:\n",
    "        model._name = 'VGG16'\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG16(input_shape, num_classes):\n",
    "    return VGGNet(input_shape=input_shape,\n",
    "                 num_classes=num_classes,\n",
    "                 model_type=16)\n",
    "\n",
    "def VGG19(input_shape, num_classes):\n",
    "    return VGGNet(input_shape=input_shape,\n",
    "                 num_classes=num_classes,\n",
    "                 model_type=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_input_shape = tf.TensorShape((None, *input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(input_shape, num_classes)\n",
    "model.build(input_shape=batch_input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG19(input_shape, num_classes)\n",
    "model.build(input_shape=batch_input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [32, 32, 3]\n",
    "\n",
    "batch_size = 16\n",
    "num_epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MiniVGGNet(input_shape, num_classes):\n",
    "    input = Input(shape=input_shape, name='Input')\n",
    "    \n",
    "    x = Conv3_64(name='block1_conv1')(input)\n",
    "    x = Conv3_64(name='block1_conv2')(x)\n",
    "    x = MaxPooling2D(pool_size=2, padding='same', name='block1_pool')(x)\n",
    "    \n",
    "    x = Conv3_128(name='block2_conv1')(x)\n",
    "    x = Conv3_128(name='block2_conv2')(x)\n",
    "    x = MaxPooling2D(pool_size=2, padding='same', name='block2_pool')(x)\n",
    "    \n",
    "    x = Conv3_256(name='block3_conv1')(x)\n",
    "    x = Conv3_256(name='block3_conv2')(x)\n",
    "    x = Conv3_256(name='block3_conv3')(x)\n",
    "    x = MaxPooling2D(pool_size=2, padding='same', name='block3_pool')(x)\n",
    "    \n",
    "    x = Conv3_512(name='block4_conv1')(x)\n",
    "    x = Conv3_512(name='block4_conv2')(x)\n",
    "    x = Conv3_512(name='block4_conv3')(x)\n",
    "    x = MaxPooling2D(pool_size=2, padding='same', name='block4_pool')(x)\n",
    "    \n",
    "    x = Conv3_512(name='block5_conv1')(x)\n",
    "    x = Conv3_512(name='block5_conv2')(x)\n",
    "    x = Conv3_512(name='block5_conv3')(x)\n",
    "    x = MaxPooling2D(pool_size=2, padding='same', name='block5_pool')(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(512, activation='relu',\n",
    "             kernel_regularizer=tf.keras.regularizers.L2(0.0005),\n",
    "             name='fc1')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(num_classes, activation='softmax', name='ouput')(x)\n",
    "\n",
    "    model = Model(inputs=input, outputs=output)\n",
    "    model._name = 'VGG_mini'\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MiniVGGNet(input_shape, num_classes)\n",
    "model.build(input_shape=batch_input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_fn(features, input_shape, augment=False):\n",
    "    \n",
    "    input_shape = tf.convert_to_tensor(input_shape)\n",
    "    \n",
    "    image = features['image']\n",
    "    label = features['label']\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    \n",
    "    if augment:\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        \n",
    "        image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "        image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
    "        image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "        \n",
    "        random_scale_factor = tf.random.uniform([1], minval=1., maxval=1.4, dtype=tf.float32)\n",
    "        scaled_height = tf.cast(tf.cast(input_shape[0], tf.float32) * random_scale_factor, tf.int32)\n",
    "        scaled_width = tf.cast(tf.cast(input_shape[1], tf.float32) * random_scale_factor, tf.int32)\n",
    "        scaled_shape = tf.squeeze(tf.stack([scaled_height, scaled_width]))\n",
    "        image = tf.image.resize(image, scaled_shape)\n",
    "        image = tf.image.random_crop(image, input_shape)\n",
    "    else:\n",
    "        image = tf.image.resize(image, input_shape[:2])\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "prepare_data_fn_for_train = functools.partial(prepare_data_fn,\n",
    "                                             input_shape=input_shape,\n",
    "                                             augment=True)\n",
    "prepare_data_fn_for_val = functools.partial(prepare_data_fn,\n",
    "                                           input_shape=input_shape,\n",
    "                                           augment=False)\n",
    "\n",
    "train_dataset = train_dataset.repeat(num_epochs) \\\n",
    "                    .shuffle(10000) \\\n",
    "                    .map(prepare_data_fn_for_train, num_parallel_calls=4) \\\n",
    "                    .batch(batch_size) \\\n",
    "                    .prefetch(1)\n",
    "\n",
    "val_dataset = val_dataset.repeat() \\\n",
    "                .map(prepare_data_fn_for_val, num_parallel_calls=4) \\\n",
    "                .batch(batch_size) \\\n",
    "                .prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './models/vggnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar100 = tf.keras.datasets.cifar100\n",
    "(_, _), (visual_images, visual_labels) = \\\n",
    "    cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_labels = ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_writer = tf.summary.create_file_writer(model_dir)\n",
    "\n",
    "def plot_to_image(figure):\n",
    "      \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "      returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "      # Save the plot to a PNG in memory.\n",
    "      buf = io.BytesIO()\n",
    "      plt.savefig(buf, format='png')\n",
    "      # Closing the figure prevents it from being displayed directly inside\n",
    "      # the notebook.\n",
    "      plt.close(figure)\n",
    "      buf.seek(0)\n",
    "      # Convert PNG buffer to TF image\n",
    "      image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "      # Add the batch dimension\n",
    "      image = tf.expand_dims(image, 0)\n",
    "      return image\n",
    "\n",
    "def image_grid():\n",
    "    test_images = tf.keras.applications.vgg16.preprocess_input(visual_images)\n",
    "    pred = model.predict(test_images)\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    figure = plt.figure(figsize=(10,10))\n",
    "    \n",
    "    random_index = random.sample(range(len(visual_images)), 25)\n",
    "    for i in range(25):\n",
    "        # Start next subplot.\n",
    "        plt.subplot(5, 5, i + 1, title=str_labels[pred[random_index[i]]])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(visual_images[random_index[i]], cmap=plt.cm.binary)\n",
    "\n",
    "    return figure\n",
    "\n",
    "def log_images(epoch, logs):\n",
    "    figure = image_grid()\n",
    "    with file_writer.as_default():\n",
    "        tf.summary.image(\"25 test data examples\", plot_to_image(figure), step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01,momentum=0.9,nesterov=True)\n",
    "accuracy_metric = tf.metrics.SparseCategoricalAccuracy(name='acc')\n",
    "top5_accuracy_metric = tf.metrics.SparseTopKCategoricalAccuracy(k=5, name='top5_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=[accuracy_metric, top5_accuracy_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss',\n",
    "                                    restore_best_weights=True),\n",
    "    \n",
    "    tf.keras.callbacks.TensorBoard(log_dir=model_dir, \n",
    "                                   histogram_freq=0, \n",
    "                                   write_graph=True,\n",
    "                                   write_images=True,\n",
    "                                   update_freq=100),\n",
    "    \n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        os.path.join(model_dir, 'weights-epoch{epoch:02d}.h5')),\n",
    "    \n",
    "    tf.keras.callbacks.LambdaCallback(on_epoch_end=log_images)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "train_steps_per_epoch = math.ceil(num_train / batch_size)\n",
    "val_steps_per_epoch = math.ceil(num_val / batch_size)\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                        epochs=num_epochs, steps_per_epoch=train_steps_per_epoch,\n",
    "                        validation_data=(val_dataset),\n",
    "                        validation_steps=val_steps_per_epoch,\n",
    "                        verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
